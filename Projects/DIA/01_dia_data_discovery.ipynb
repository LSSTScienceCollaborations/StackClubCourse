{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discovery notebook for Diff image analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If its actually needed, we will set up this notebook to find datasets that are suitable for constructing difference images.  e.g., when given a repository, construct a catalog of calexps and their corresponding coadds that could be used as a diff image template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pa\n",
    "\n",
    "REPO = '/project/mrawls/hits2015/rerun/coaddtest1/'  \n",
    "from lsst.daf.persistence import Butler\n",
    "butler = Butler(REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = butler.queryMetadata('src',['visit','ccd','filter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId={'visit': int(metadata[0][0]), 'ccd':int(metadata[0][1]), 'filter':metadata[0][2]}\n",
    "butler.datasetExists('src', dataId=dataId) #Return True if the Dataset is actually present in the Datastore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId={'visit': 410915, 'ccd': 33, 'filter': 'g'} #This dataId exists\n",
    "butler.datasetExists('src', dataId=dataId) #Return True if the Dataset is actually present in the Datastore.\n",
    "srcCatalog = butler.get('src', dataId=dataId).asAstropy().to_pandas() # get the source catalog\n",
    "srcCatalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_catalog = butler.get('src', dataId=dataId) # get the source catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowData = []\n",
    "for dataset in metadata:\n",
    "    dataId = {'visit': int(dataset[0]), 'ccd': int(dataset[1]), 'filter':dataset[2]}\n",
    "    if butler.datasetExists('src', dataId=dataId):\n",
    "        srcCatalog = butler.get('src', dataId=dataId).asAstropy().to_pandas() # get the source catalog\n",
    "        raMax = srcCatalog['coord_ra'].max()\n",
    "        raMin = srcCatalog['coord_ra'].min()\n",
    "        decMax = srcCatalog['coord_dec'].max()\n",
    "        decMin = srcCatalog['coord_dec'].min()\n",
    "        raCenter = 0.5*(raMax + raMin)\n",
    "        decCenter = 0.5*(decMax + decMin)\n",
    "        rowData.append([int(dataset[1]), int(dataset[1]), dataset[2], raCenter, decCenter, \n",
    "                  raMin, raMax, decMin, decMax])\n",
    "        \n",
    "df_valid_visists = pd.DataFrame(rowData, columns=['visit', 'ccd', 'DECAM_filter', 'ra_center', 'dec_center', \n",
    "                                        'ra_min', 'ra_max', 'dec_min', 'dec_max'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_save_path = '/home/mrabus/notebooks/Stack_club_project/StackClubCourse/Projects/DIA'\n",
    "df_valid_visists.to_parquet( os.path.join(parquet_save_path,'df.parquet.gzip'), compression='gzip')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
